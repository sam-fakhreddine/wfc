Base directory for this skill: /Users/samfakhreddine/.claude/skills/wfc-pr-comments

# WFC:PR-COMMENTS - Intelligent PR Comment Triage & Fix

**Fetch, triage, fix.** Automates addressing PR review comments from humans, Copilot, CodeRabbit, and other reviewers.

## What It Does

1. **Fetch** all PR comments via `gh` CLI
2. **Triage** each comment against 5 validity criteria
3. **Present** triage summary to user for approval
4. **Fix** valid comments in parallel (subagents by category)
5. **Commit & push** fixes to the PR branch

## Usage

```bash
# Auto-detect PR from current branch
/wfc-pr-comments

# Specific PR number
/wfc-pr-comments 42

# PR URL
/wfc-pr-comments https://github.com/owner/repo/pull/42
```

---

## Workflow

Follow these steps exactly in order.

### Step 1: DETECT PR

Determine which PR to work on:

1. If the user provided a PR number or URL as argument, use that.
2. Otherwise, auto-detect from the current branch:

```bash
gh pr view --json number,url,headRefName,baseRefName,title
```

If no PR is found, tell the user and stop.

Display: `PR #N: <title> (<head> -> <base>)`

### Step 2: FETCH UNRESOLVED COMMENTS

Fetch only **unresolved** review comments from the PR. Use GraphQL â€” the REST API does not expose thread resolution status.

```bash
gh api graphql -f query='
  query($owner: String!, $repo: String!, $number: Int!) {
    repository(owner: $owner, name: $repo) {
      pullRequest(number: $number) {
        reviewThreads(first: 100) {
          nodes {
            isResolved
            isOutdated
            path
            line
            startLine
            diffSide
            comments(first: 50) {
              nodes {
                id
                body
                author { login }
                createdAt
                path
                diffHunk
                originalLine
              }
            }
          }
        }
      }
    }
  }
' -f owner='{owner}' -f repo='{repo}' -F number={number}
```

**Filter:** Only process threads where `isResolved` is `false`. Skip all resolved threads entirely â€” they have already been addressed.

Optionally also skip threads where `isOutdated` is `true` (the code has changed since the comment was made), but flag these to the user in the triage table.

Extract from each unresolved thread's first comment:
- `id` â€” unique identifier
- `author.login` â€” who wrote it
- `body` â€” comment text
- `path` â€” file being commented on
- `line` / `originalLine` â€” line number
- `diffHunk` â€” surrounding diff context
- `createdAt` â€” timestamp

**Deduplication:** If two threads reference the same file + line + substantially identical message, treat them as one.

**Group by file** for display purposes.

If there are zero unresolved comments, tell the user "All review threads are resolved" and stop.

### Step 3: TRIAGE

This is the core intelligence. For each comment, evaluate 5 dimensions and assign a verdict.

**Read each file being commented on** before evaluating (use the Read tool).

#### Dimension 1: ARCHITECTURAL VALIDITY

Does this suggestion align with project patterns?
- Check existing conventions in the file and codebase
- Consider CLAUDE.md / PLANNING.md rules
- A suggestion that contradicts project conventions â†’ lean toward SKIP

#### Dimension 2: SCOPE CHECK

Is this about code in this PR's diff, or asking for unrelated work?
- Comment about code changed in this PR â†’ in scope
- Request for unrelated refactoring â†’ out of scope â†’ SKIP
- Feature request disguised as review comment â†’ SKIP

#### Dimension 3: CORRECTNESS

Is the suggested fix actually correct?
- Would implementing it introduce bugs?
- Does it handle edge cases the reviewer may have missed?
- Is the reviewer wrong about the issue? If so â†’ SKIP with explanation

#### Dimension 4: SEVERITY

- **Critical** (security, data loss, crashes) â†’ always FIX
- **High** (bugs, logic errors) â†’ FIX
- **Medium** (code quality, patterns) â†’ FIX if valid
- **Low** (style, preferences) â†’ FIX if trivial, SKIP if opinionated
- **Info** (questions, suggestions) â†’ RESPOND only

#### Dimension 5: EFFORT vs VALUE

- **Trivial** (1-2 lines) â†’ always FIX
- **Medium** (function-level) â†’ FIX if high value
- **Large** (multi-file refactor) â†’ SKIP, suggest follow-up issue

**Verdict per comment:** `FIX` | `SKIP (reason)` | `RESPOND (reply only)`

### Step 4: PRESENT TRIAGE TO USER

Display a markdown table summarizing the triage:

```
| # | File | Comment (summary) | Verdict | Reason |
|---|------|-------------------|---------|--------|
| 1 | security_hook.py:45 | Add lru_cache to pattern loading | FIX | Valid perf improvement, trivial |
| 2 | orchestrator.py:120 | Rewrite auth flow | SKIP | Out of scope for this PR |
| 3 | README.md:8 | Fix typo "teh" â†’ "the" | FIX | Trivial |
| 4 | consensus.py:30 | Why not use dataclass? | RESPOND | Question, not actionable |
```

Then show summary counts:

```
Summary: 8 FIX, 2 SKIP, 1 RESPOND

Proceed with fixes?
```

**Use AskUserQuestion** to get approval. The user may:
- Approve as-is
- Override specific verdicts (e.g., "skip #1, fix #4")
- Cancel entirely

Apply any user overrides before proceeding.

### Step 5: CATEGORIZE & DELEGATE

Group all `FIX` comments into categories:

| Category | Examples |
|----------|----------|
| **Lint** | Unused imports, formatting, naming conventions |
| **Code Quality** | Caching, error handling, type safety, simplification |
| **Design** | Architecture changes, API modifications, patterns |
| **Docs** | Typos, missing docs, outdated comments |
| **Security** | Vulnerabilities, hardcoded secrets, input validation |

Spawn **1 subagent per category** via the Task tool (run in parallel).

Each subagent receives this prompt:

```
You are fixing PR review comments in category: {category}

PR: #{number} on branch {headRefName}
Repository root: {repo_root}

Comments to address:
{for each comment in this category:}
---
File: {path}:{line}
Comment by {author}: {body}
Diff context:
{diff_hunk}
---
{end for}

Instructions:
1. Read each file mentioned above
2. Apply the fix described in each comment
3. Verify the fix is correct â€” do not introduce regressions
4. Run relevant tests if they exist (use: uv run pytest {test_file} -v)
5. Do NOT fix anything not in the comment list above
6. Do NOT make unrelated improvements or refactors
```

For `RESPOND` comments: Do NOT spawn a subagent. Instead, after fixes are committed, use `gh api` to reply to the comment on GitHub with an explanation.

### Step 6: COMMIT & PUSH

After all fix subagents complete:

1. Check which files were modified: `git status`
2. Stage all fixed files (by name, not `git add -A`)
3. Create a single commit:

```
fix: address N PR review comments

- {file1}: {brief description of fix}
- {file2}: {brief description of fix}
...

Addresses comments on PR #{number}

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>
```

4. Push to the PR branch:

```bash
git push origin {headRefName}
```

### Step 7: REPORT

Display a final summary:

```
## PR Comment Fixes Complete

**PR:** #{number} â€” {title}
**Branch:** {headRefName}

### Fixed (N comments)
- {file}:{line} â€” {brief fix description}
- ...

### Skipped (N comments)
- {file}:{line} â€” {reason}
- ...

### Responded (N comments)
- {file}:{line} â€” {reply summary}
- ...

Pushed to {headRefName}. PR updated.
```

---

## Integration with WFC

### Fits After
- `wfc-build` or `wfc-implement` (which create PRs)
- Any workflow that pushes a branch and creates a PR

### Complements
- `wfc-review` â€” internal review BEFORE creating a PR
- `wfc-pr-comments` â€” external feedback AFTER PR is created

### Typical Flow
```
wfc-build â†’ Push PR â†’ Reviewers comment â†’ /wfc-pr-comments â†’ Push fixes â†’ Merge
```

## Philosophy

**ELEGANT:** Single skill replaces manual comment-by-comment triage
**PARALLEL:** Fix subagents run concurrently by category
**TOKEN-AWARE:** Only reads files that have comments, not the entire codebase
**SAFE:** User approval gate before any fixes are applied


ARGUMENTS: https://github.com/sam-fakhreddine/wfc/pull/15

---

check for merge conflicts and fix them

---

create a new PR that brings in PR15 and PR17

---

Base directory for this skill: /Users/samfakhreddine/.claude/skills/wfc-review

# WFC:CONSENSUS-REVIEW - Five-Agent Consensus Code Review

Five fixed reviewers analyze code and a Consensus Score determines the decision.

## What It Does

1. **Security Reviewer** - Injection, auth/authz, OWASP Top 10
2. **Correctness Reviewer** - Logic bugs, edge cases, type safety
3. **Performance Reviewer** - Algorithmic efficiency, N+1 queries, memory
4. **Maintainability Reviewer** - Readability, naming, SOLID/DRY, complexity
5. **Reliability Reviewer** - Error handling, fault tolerance, graceful degradation
6. **Consensus Score (CS)** - Weighted formula with Minority Protection Rule

## Usage

```bash
# Review specific task
/wfc-consensus-review TASK-001

# Review files directly
/wfc-consensus-review path/to/code

# With properties
/wfc-consensus-review TASK-001 --properties PROP-001,PROP-002
```

## Two-Phase Workflow

### Phase 1: Prepare Review
```
orchestrator.prepare_review(request) -> 5 task specs
```
Builds prompts for each reviewer with file list, diff, properties, and knowledge context. Irrelevant reviewers (based on file extensions) are marked for skipping.

### Phase 2: Finalize Review
```
orchestrator.finalize_review(request, responses, output_dir) -> ReviewResult
```
1. Parse subagent responses into findings
2. Deduplicate findings across reviewers (SHA-256 fingerprinting with +/-3 line tolerance)
3. Calculate Consensus Score
4. Generate markdown report

## Consensus Score (CS) Formula

```
CS = (0.5 * R_bar) + (0.3 * R_bar * (k/n)) + (0.2 * R_max)
```

Where:
- **R_i** = (severity * confidence) / 10 for each deduplicated finding
- **R_bar** = mean of all R_i values
- **k** = total reviewer agreements (sum of per-finding reviewer counts)
- **n** = 5 (total reviewers)
- **R_max** = max(R_i) across all findings

## Decision Tiers

| Tier | CS Range | Action |
|------|----------|--------|
| Informational | CS < 4.0 | Log only, review passes |
| Moderate | 4.0 <= CS < 7.0 | Inline comment, review passes |
| Important | 7.0 <= CS < 9.0 | Block merge, review fails |
| Critical | CS >= 9.0 | Block + escalate, review fails |

## Minority Protection Rule (MPR)

Prevents a single critical finding from being diluted by many clean reviews:

```
IF R_max >= 8.5 AND k >= 1 AND finding is from security/reliability:
    CS_final = max(CS, 0.7 * R_max + 2.0)
```

## Finding Deduplication

Findings from different reviewers pointing to the same issue are merged:
- **Fingerprint**: SHA-256 of `file:normalized_line:category` (line tolerance +/-3)
- **Merge**: highest severity wins, all descriptions and remediations preserved
- **k tracking**: number of reviewers who flagged the same issue (increases CS)

## Output

### Review Report (REVIEW-TASK-XXX.md)

```markdown
# Review Report: TASK-001

**Status**: PASSED
**Consensus Score**: CS=3.50 (informational)
**Reviewers**: 5
**Findings**: 2

---

## Reviewer Summaries

### PASS: Security Reviewer
**Score**: 10.0/10
**Summary**: No security issues found.
**Findings**: 0

### PASS: Correctness Reviewer
**Score**: 8.5/10
**Summary**: Minor edge case.
**Findings**: 1

...

---

## Findings

### [MODERATE] src/auth.py:45
**Category**: validation
**Severity**: 5.0
**Confidence**: 7.0
**Reviewers**: correctness, reliability (k=2)
**R_i**: 3.50

**Description**: Missing input validation on user_id

**Remediation**:
- Add type check and bounds validation

---

## Summary

CS=3.50 (informational): 2 finding(s), review passed.
```

## Integration with WFC

### Called By
- `wfc-implement` - After agent completes TDD workflow

### Consumes
- Task files (from git worktree)
- PROPERTIES.md (formal properties to verify)
- Git diff content

### Produces
- Review report (REVIEW-{task_id}.md)
- Consensus Score decision (pass/fail with tier)
- Deduplicated findings with reviewer agreement counts

## Relevance Gate

Each reviewer has domain-specific file extensions. Only relevant reviewers execute:

| Reviewer | Relevant Extensions |
|----------|-------------------|
| Security | .py, .js, .ts, .go, .java, .rb, .php, .rs |
| Correctness | .py, .js, .ts, .go, .java, .rb, .rs, .c, .cpp |
| Performance | .py, .js, .ts, .go, .java, .rs, .sql |
| Maintainability | * (always relevant) |
| Reliability | .py, .js, .ts, .go, .java, .rs |

## Philosophy

**ELEGANT**: Simple two-phase workflow, deterministic reviewer set
**MULTI-TIER**: Engine (logic) separated from CLI (presentation)
**PARALLEL**: 5 reviewers can run concurrently via Task tool
**TOKEN-AWARE**: Relevance gate skips irrelevant reviewers

---

continue

---

please fix the issues with the code

---

[Request interrupted by user]

---

Base directory for this skill: /Users/samfakhreddine/.claude/skills/wfc-build

# WFC:BUILD - Intentional Vibe Coding

**"Vibe coding with guardrails"** - Quick iteration with WFC quality standards.

## What It Does

Simplified workflow that skips formal planning but maintains all WFC quality infrastructure:

1. **Adaptive Interview** - Quick clarifying questions (not full wfc-plan)
2. **Complexity Assessment** - Orchestrator decides: 1 agent or multi-agent?
3. **Subagent Delegation** - Spawn subagent(s) via Task tool (orchestrator NEVER implements)
4. **TDD Workflow** - Each subagent follows TEST â†’ IMPLEMENT â†’ REFACTOR
5. **Quality Gates** - Formatters, linters, tests (pre-review)
6. **Consensus Review** - Route through wfc-review
7. **Auto-Merge** - Merge to develop via PR (or rollback on failure)

## Usage

```bash
# Default: orchestrator asks clarifying questions
/wfc-build

# With description
/wfc-build "add progressive doc loader"

# With context
/wfc-build "add OAuth2 authentication to FastAPI backend"
```

## "Intentional Vibe" Philosophy

**Vibe Coding:**
- Fast iteration
- Minimal planning
- Just ship it

**+ WFC Guardrails:**
- Git worktrees (isolation)
- TDD workflow (tests first)
- Quality checks (formatters, linters)
- Consensus review (multi-agent)
- Auto-rollback (safety)

**= Intentional Vibe:**
- Quick enough to flow
- Structured enough to be safe
- Professional enough to ship

## Adaptive Interview

Orchestrator asks 3-5 quick questions:

```
Q1: What are you building?
A: Progressive documentation loader

Q2: Which files should this touch?
A: New files in wfc/shared/ and scripts/docs/

Q3: Expected behavior?
A: Load doc summaries, fetch full content on-demand

Q4: Tech stack?
A: Python, similar to persona_loader.py pattern
```

Then orchestrator assesses complexity and spawns subagent(s).

## Complexity Assessment

Orchestrator decides based on scope:

### Simple Task â†’ 1 Subagent

**Examples:**
- "add a utility function"
- "create a doc loader"
- "fix a bug"
- "add a new endpoint"

**Flow:**
```
Spawn 1 subagent via Task tool
    â†“
Subagent implements in worktree (TDD)
    â†“
Quality check â†’ Review â†’ Merge
```

### Complex Task â†’ N Subagents

**Examples:**
- "add OAuth2 authentication" (backend + frontend + security)
- "build a dashboard" (API + UI + charts)
- "refactor auth system" (multiple components)

**Flow:**
```
Spawn N subagents via Task tool (parallel)
    â†“
Subagent 1: Backend API (worktree-1)
Subagent 2: Frontend UI (worktree-2)
Subagent 3: Security validation (worktree-3)
    â†“
Each: TDD â†’ Quality â†’ Review
    â†“
Merge sequentially
```

## Orchestrator Responsibilities

**What orchestrator DOES:**
- âœ… Ask clarifying questions
- âœ… Assess task complexity
- âœ… Decide: 1 agent or N agents?
- âœ… Spawn subagent(s) via Task tool
- âœ… Wait for subagent completion
- âœ… Route through quality + review
- âœ… Coordinate merge/rollback

**What orchestrator NEVER DOES:**
- âŒ Write code
- âŒ Write tests
- âŒ Run formatters/linters
- âŒ Implement anything

**Critical Principle:** Orchestrator coordinates, NEVER implements.

## Subagent Workflow (Per Agent)

Each subagent follows TDD in isolated worktree:

```
1. UNDERSTAND
   - Read orchestrator's task spec
   - Review related files
   - Understand context

2. TEST_FIRST (RED)
   - Write tests BEFORE code
   - Run tests â†’ FAIL

3. IMPLEMENT (GREEN)
   - Write minimum code to pass
   - Run tests â†’ PASS

4. REFACTOR
   - Clean up code
   - Run tests â†’ still PASS

5. QUALITY_CHECK
   - Run formatters (black, prettier, etc.)
   - Run linters (ruff, eslint, etc.)
   - Run tests
   - Blocks if checks fail

6. SUBMIT
   - Produce agent report
   - Return to orchestrator
```

## Architecture

```
User: /wfc-build "add doc loader"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ORCHESTRATOR (coordinates only)    â”‚
â”‚  - Ask clarifying questions         â”‚
â”‚  - Assess complexity                â”‚
â”‚  - Decide: 1 or N agents?           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Simple  â”‚ Complex â”‚
    â†“          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1 Sub â”‚  â”‚ N Subagents (parallel)â”‚
â”‚ agent â”‚  â”‚ - Agent 1 (backend)  â”‚
â”‚       â”‚  â”‚ - Agent 2 (frontend) â”‚
â”‚       â”‚  â”‚ - Agent 3 (security) â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    Each agent (isolated):
    - Git worktree
    - TDD workflow
    - Quality check
    - Submit report
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ORCHESTRATOR (coordinates)    â”‚
â”‚  - Wait for completion         â”‚
â”‚  - Route through wfc-review    â”‚
â”‚  - Merge (or rollback)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Integration with WFC

### Uses (delegates to):
- **Git worktrees** - Isolated implementation environments
- **Quality checker** - Pre-review gates (formatters, linters, tests)
- **wfc-review** - Consensus review with expert personas
- **Merge engine** - Auto-merge with rollback capability

### Produces:
- PR targeting develop branch (auto-merge for agent branches)
- Agent reports (telemetry)
- Review reports

### Skips:
- Formal TASKS.md generation
- Multi-tier planning
- Property formalization (uses lightweight acceptance criteria instead)

## When to Use

### Use wfc-build when:
- âœ… Single feature or small addition
- âœ… Want to iterate quickly
- âœ… Scope is clear from description
- âœ… "Just build this and ship it"

### Use wfc-plan + wfc-implement when:
- âœ… Large feature with multiple tasks
- âœ… Complex dependencies
- âœ… Need formal properties (SAFETY, LIVENESS, etc.)
- âœ… Multi-week effort

## Configuration

```json
{
  "build": {
    "interview_questions": 5,
    "complexity_threshold": "auto",
    "max_agents": 3,
    "enforce_tdd": true,
    "require_quality_check": true,
    "require_review": true
  }
}
```

## Example Session

```
User: /wfc-build "add rate limiting to API"

Orchestrator:
  Q: What's the main goal?
  A: Prevent API abuse, 100 requests/minute per user

  Q: Which endpoints?
  A: All /api/* endpoints

  Q: Tech stack?
  A: FastAPI, Redis for rate limit storage

  Q: Expected behavior on limit exceeded?
  A: Return 429 Too Many Requests

Orchestrator: Assessing complexity...
  â†’ SIMPLE task (single component)
  â†’ Spawning 1 subagent

Subagent-1 (worktree-1):
  âœ… TEST_FIRST: Write rate limit tests
  âœ… IMPLEMENT: Add FastAPI middleware + Redis client
  âœ… REFACTOR: Extract config, clean up
  âœ… QUALITY_CHECK: black, ruff, pytest â†’ PASS
  âœ… SUBMIT: Agent report ready

Orchestrator:
  âœ… Route to wfc-review (5 personas)
  âœ… Consensus: APPROVED (8.5/10)
  âœ… Merge to main
  âœ… Integration tests: PASS

Done! âœ… Rate limiting added to API
```

## Philosophy

**ELEGANT:** Simple orchestration, clear delegation, no over-engineering
**INTENTIONAL:** Vibe coding + WFC guardrails = professional quality
**DELEGATED:** Orchestrator NEVER implements, ALWAYS delegates

## Git Workflow Policy (PR-First)

WFC creates feature branches, pushes them, and opens GitHub PRs for team review.

```
WFC workflow:
  Build -> Quality -> Review -> Push Branch -> Create GitHub PR to develop
                                                    |
                                              [WFC STOPS HERE]
                                                    |
                                  Auto-merge for claude/* branches
                                  Manual review for feat/* branches
```

Agent branches (claude/*) auto-merge to develop when CI passes. Human branches require manual review. Release candidates are cut from develop to main on a schedule.

**What WFC does:**
- Creates feature branches
- Pushes branches to remote
- Creates GitHub PRs targeting develop (draft by default)

**What WFC never does:**
- Push directly to main/master
- Force push
- Merge PRs to main (you decide when to cut releases)

**Legacy mode:** Set `"merge.strategy": "direct"` in wfc.config.json for local-only merge.

See [GIT_SAFETY_POLICY.md](../../../docs/security/GIT_SAFETY_POLICY.md) for complete policy.

---

**This is Intentional Vibe.** ðŸŽ¯

Fast enough to flow. Structured enough to ship. Safe enough to trust.


ARGUMENTS: fix these   Top Findings (Must-Fix)

  ðŸ”´ CRITICAL / HIGH (Severity â‰¥ 7.5)

  1. emergency_bypass.py:79 â€” _audit_dir not created before mkstemp() â†’ FileNotFoundError on first use (Reliability, sev 8.5)
  2. emergency_bypass.py:109 â€” _load_raw() has no json.JSONDecodeError handling â†’ one corrupt record disables all bypass operations (Reliability, sev 8.0)
  3. emergency_bypass.py:122 â€” _dict_to_record() bare key access â†’ KeyError on malformed record crashes load_audit_trail() (Reliability, sev 7.5)
  4. rag_engine.py:41 â€” _JsonVectorStore.__init__ crashes on malformed vectors.json with no recovery (Reliability, sev 8.0)
  5. rag_engine.py:87 â€” non-atomic write to vectors.json â†’ partial file on crash (Reliability, sev 7.5)
  6. rag_engine.py:295 â€” _load_hashes() crashes RAGEngine constructor on corrupt hash file (Reliability, sev 7.5)
  7. reviewer_engine.py:270 â€” non-greedy regex silently truncates findings arrays containing ] in descriptions (Correctness, sev 8.5) â€” k=3
  8. knowledge_writer.py:163 â€” prune_old_entries() no error handling + date.fromisoformat() can crash entire prune (Reliability, sev 7.0)
  9. fingerprint.py:76 â€” bare dict key access aborts entire dedup on one malformed finding (Reliability, sev 7.0) â€” k=2
  10. drift_detector.py:192 â€” path traversal: user-controlled file stem from KNOWLEDGE.md joined to project root without containment check (Security, sev 7.5)
  11. reviewer_engine.py:229 â€” unsanitized diff content injected into LLM prompt â†’ prompt injection (OWASP LLM01) (Security, sev 7.0) â€” k=2
  12. ast_analyzer.py:289 â€” import x.y always reported as unused (false positive via wrong key in imported dict) (Correctness, sev 6.0)
  13. eval_judge.py:80 â€” true-negative case returns precision=0.0 corrupting benchmark metrics (Correctness, sev 7.5)
  14. knowledge_writer.py:108 â€” N full read+write cycles for N entries in one batch (Performance, sev 7.5) â€” k=2

  ðŸŸ¡ SHOULD-FIX (Severity 5.0â€“7.4)

  15. knowledge_writer.py:155 â€” stored prompt injection via unsanitized entry.text in KNOWLEDGE.md (Security, sev 5.0)
  16. rag_engine.py:75 â€” O(n) cosine similarity linear scan, no indexing (Performance, sev 8.5) â€” architectural
  17. ast_analyzer.py:261 â€” ast.withitem counted instead of ast.With inflates complexity by 2Ã— (Correctness, sev 6.0)
  18. finding_validator.py:132 â€” Layer 2 cross-check spec built but silently discarded, dead code (Maintainability, sev 6.0)
  19. eval_judge.py:172 â€” dual-judge always produces identical scores, agreement is meaningless (Correctness + Maintainability, sev 6.5)
  20. embeddings.py:71 â€” TfidfEmbeddings.embed([]) raises ValueError on empty texts (Reliability, sev 5.5)
  21. drift_detector.py:70 â€” missing encoding="utf-8" on 6+ read_text() calls (Security, sev 3.5)